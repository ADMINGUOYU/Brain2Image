# Imports
import os
import torch
import pandas as pd
import numpy as np
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import HDBSCAN 
from sentence_transformers import SentenceTransformer

# =========================================================
# ğŸ’¡ å…¨å±€æ§åˆ¶å¼€å…³
# =========================================================
DO_CLUSTERING = False 
# =========================================================

# ---------------------------------------------------------
# 1. è®¾ç½® Hugging Face ç¯å¢ƒå˜é‡
# ---------------------------------------------------------
os.environ["HF_HOME"] = "/mnt/afs/250010218/hf_cache" 
# os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# ---------------------------------------------------------
# 2. è¯»å– EEG æ•°æ®åŠå¯¹åº”æ ‡ç­¾
# ---------------------------------------------------------
processed_dir = "datasets/processed"
os.makedirs(processed_dir, exist_ok=True) 

output_plot_dir = 'preprocess/label_refine'
os.makedirs(output_plot_dir, exist_ok=True)

things_images_df_path = os.path.join(processed_dir, "things_images_df.pkl")
things_images_df: pd.DataFrame = pd.read_pickle(things_images_df_path)

print("DataFrame Columns:", things_images_df.columns)
class_labels = things_images_df['class_label'].unique()
labels_list = class_labels.tolist()

# ---------------------------------------------------------
# ğŸ’¡ å®šä¹‰è¦å¯¹æ¯”çš„æ¨¡å‹å­—å…¸ {æ¨¡å‹HFè·¯å¾„ : åˆ«å(ç”¨äºå‘½å)}
# ---------------------------------------------------------
models_to_run = {
    'all-MiniLM-L6-v2': 'minilm',
    'clip-ViT-B-32': 'clip'
}

# å¼€å§‹éå†ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”å®éªŒ
for model_name, model_alias in models_to_run.items():
    print("\n" + "="*60)
    print(f"ğŸš€ å½“å‰æ­£åœ¨å¤„ç†æ¨¡å‹: {model_name}")
    print("="*60)

    # ---------------------------------------------------------
    # 3. æå–ç‰¹å¾
    # ---------------------------------------------------------
    print(f"æ­£åœ¨åŠ è½½æ–‡æœ¬ç‰¹å¾æå–æ¨¡å‹ ({model_name})...")
    # SBERT åŸç”Ÿæ”¯æŒåŠ è½½ CLIP æ¨¡å‹è¿›è¡Œ Text ç¼–ç 
    text_model = SentenceTransformer(model_name) 

    print("æ­£åœ¨è®¡ç®— labels çš„è¯­ä¹‰ embeddings...")
    embeddings = text_model.encode(labels_list, show_progress_bar=True) 

    # ---------------------------------------------------------
    # 4. HDBSCAN å¯†åº¦èšç±» (å— DO_CLUSTERING æ§åˆ¶)
    # ---------------------------------------------------------
    if DO_CLUSTERING:
        print("æ­£åœ¨ä½¿ç”¨ HDBSCAN è¿›è¡Œè¯­ä¹‰å¯†åº¦èšç±»...")
        hdbscan_model = HDBSCAN(min_cluster_size=10, min_samples=3)
        cluster_ids = hdbscan_model.fit_predict(embeddings)

        n_clusters_ = len(set(cluster_ids)) - (1 if -1 in cluster_ids else 0)
        n_noise_ = list(cluster_ids).count(-1)

        print(f"[{model_alias}] è‡ªåŠ¨å‘ç°äº† {n_clusters_} ä¸ªèšç±»ç°‡ã€‚")
        print(f"[{model_alias}] è¢«æ ‡è®°ä¸ºå™ªå£° (æœªå½’ç±») çš„è¯­ä¹‰æ•°é‡: {n_noise_}")
    else:
        print("DO_CLUSTERING ä¸º Falseï¼Œè·³è¿‡èšç±»é˜¶æ®µ...")

    # ---------------------------------------------------------
    # 5. PCA é™ç»´ (3 ç»´ï¼Œæ”¯æŒ 2D å’Œ 3D)
    # ---------------------------------------------------------
    print("æ­£åœ¨è¿›è¡Œ PCA é™ç»´å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    pca = PCA(n_components=3, random_state=42)
    embeddings_pca = pca.fit_transform(embeddings)

    # =========================================================
    # 5.1 ç”Ÿæˆ 2D å¯è§†åŒ–å›¾è¡¨
    # =========================================================
    plt.figure(figsize=(12, 10))

    if DO_CLUSTERING:
        noise_mask = (cluster_ids == -1)
        clustered_mask = (cluster_ids != -1)

        plt.scatter(embeddings_pca[noise_mask, 0], embeddings_pca[noise_mask, 1], 
                    c='gray', s=20, alpha=0.3, edgecolors='none', label='Noise/Outliers')
        plt.scatter(embeddings_pca[clustered_mask, 0], embeddings_pca[clustered_mask, 1], 
                    c=cluster_ids[clustered_mask], cmap='tab20', s=40, alpha=0.8, edgecolors='none')

        plt.title(f'PCA 2D Projection ({model_name})\n{n_clusters_} Clusters Found', fontsize=16, fontweight='bold')
        plt.legend(loc='best')
        plot_filename_2d = f"semantic_clusters_pca_2d_{model_alias}.png"
    else:
        plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], 
                    c='steelblue', s=30, alpha=0.7, edgecolors='none')
        plt.title(f'PCA 2D Projection of THINGS Concepts ({model_name})\n(No Clustering)', fontsize=16, fontweight='bold')
        plot_filename_2d = f"semantic_pca_2d_{model_alias}_no_clustering.png"

    plt.xlabel('Principal Component 1', fontsize=12)
    plt.ylabel('Principal Component 2', fontsize=12)

    for i, label in enumerate(labels_list):
        if i % 30 == 0:  
            plt.annotate(label, (embeddings_pca[i, 0], embeddings_pca[i, 1]), 
                         fontsize=9, alpha=0.8, xytext=(3, 3), textcoords='offset points')

    ax = plt.gca()
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

    plt.tight_layout()
    plot_path_2d = os.path.join(output_plot_dir, plot_filename_2d)
    plt.savefig(plot_path_2d, dpi=300, bbox_inches='tight')
    print(f"2D å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³ {plot_path_2d}")
    plt.close() # é‡Šæ”¾å†…å­˜é¿å…å¤šå›¾é‡å 

    # =========================================================
    # 5.2 ç”Ÿæˆ 3D å¯è§†åŒ–å›¾è¡¨
    # =========================================================
    fig = plt.figure(figsize=(12, 10))
    ax3d = fig.add_subplot(111, projection='3d')

    if DO_CLUSTERING:
        ax3d.scatter(embeddings_pca[noise_mask, 0], embeddings_pca[noise_mask, 1], embeddings_pca[noise_mask, 2],
                     c='gray', s=20, alpha=0.3, edgecolors='none', label='Noise/Outliers')
        ax3d.scatter(embeddings_pca[clustered_mask, 0], embeddings_pca[clustered_mask, 1], embeddings_pca[clustered_mask, 2],
                     c=cluster_ids[clustered_mask], cmap='tab20', s=40, alpha=0.8, edgecolors='none')

        ax3d.set_title(f'PCA 3D Projection ({model_name})\n{n_clusters_} Clusters Found', fontsize=16, fontweight='bold')
        ax3d.legend(loc='best')
        plot_filename_3d = f"semantic_clusters_pca_3d_{model_alias}.png"
    else:
        ax3d.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], embeddings_pca[:, 2],
                     c='steelblue', s=30, alpha=0.7, edgecolors='none')
        ax3d.set_title(f'PCA 3D Projection of THINGS Concepts ({model_name})', fontsize=16, fontweight='bold')
        plot_filename_3d = f"semantic_pca_3d_{model_alias}_no_clustering.png"

    ax3d.set_xlabel('Principal Component 1', fontsize=12)
    ax3d.set_ylabel('Principal Component 2', fontsize=12)
    ax3d.set_zlabel('Principal Component 3', fontsize=12)

    for i, label in enumerate(labels_list):
        if i % 30 == 0:  
            ax3d.text(embeddings_pca[i, 0], embeddings_pca[i, 1], embeddings_pca[i, 2], 
                      label, fontsize=9, alpha=0.8)

    plt.tight_layout()
    plot_path_3d = os.path.join(output_plot_dir, plot_filename_3d)
    plt.savefig(plot_path_3d, dpi=300, bbox_inches='tight')
    print(f"3D å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³ {plot_path_3d}")
    plt.close() # é‡Šæ”¾å†…å­˜

    # ---------------------------------------------------------
    # 6 & 7. åç»­å¤„ç† (ä»…åœ¨èšç±»æ—¶æ‰§è¡Œ)
    # ---------------------------------------------------------
    if DO_CLUSTERING:
        label_to_cluster = {}
        for i, label in enumerate(labels_list):
            if cluster_ids[i] == -1:
                label_to_cluster[label] = "Noise_Outlier"
            else:
                label_to_cluster[label] = f"Cluster_{cluster_ids[i]}"

        # åŠ¨æ€æ·»åŠ åˆ—åï¼Œé¿å…è¦†ç›– (e.g., high_level_label_clip)
        col_name = f'high_level_label_{model_alias}'
        things_images_df[col_name] = things_images_df['class_label'].map(label_to_cluster)
        print(f"å·²æˆåŠŸå°† High-level labels æ˜ å°„è‡³æ–°åˆ—: {col_name}ï¼")
        
        print("\n" + "-"*50)
        print(f"=== {model_alias.upper()} æ¨¡å‹èšç±»ç°‡ä»£è¡¨æ€§æ ‡ç­¾ ===")
        print("-"*50)

        cluster_typical_labels = {}
        for c in range(n_clusters_):
            idx_in_cluster = np.where(cluster_ids == c)[0]
            cluster_embs = embeddings[idx_in_cluster]
            centroid = np.mean(cluster_embs, axis=0)
            distances = np.linalg.norm(cluster_embs - centroid, axis=1)
            
            typical_idx_relative = np.argmin(distances)
            typical_idx_absolute = idx_in_cluster[typical_idx_relative]
            typical_label = labels_list[typical_idx_absolute]
            
            closest_indices_relative = np.argsort(distances)[:5]
            closest_words = [labels_list[idx_in_cluster[i]] for i in closest_indices_relative]
            
            cluster_typical_labels[f"Cluster_{c}"] = typical_label
            print(f"Cluster {c} (åŒ…å« {len(idx_in_cluster)} ä¸ªè¯):")
            print(f"  ğŸ¯ Typical Label : {typical_label}")
            print(f"  ğŸ“š æ ¸å¿ƒè¯æ±‡ç¾¤    : {', '.join(closest_words)}\n")

if DO_CLUSTERING:
    print("\næ‰€æœ‰æ¨¡å‹å¤„ç†å®Œæ¯•ã€‚DataFrame å‰ 5 è¡Œå±•ç¤º:")
    display_cols = ['class_label', 'high_level_label_minilm', 'high_level_label_clip']
    print(things_images_df[display_cols].head())