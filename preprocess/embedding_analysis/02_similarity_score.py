# This is the second step of the embedding analysis pipeline.
# It would compute similarity scores of the generated 4096
# fMRI embeddings (by MindEYE2 shared latent MLP):
#    a) for each subject, similarity scores between fMRI embeddings
#       of the same image (across sessions), we have 3 trials for each
#       image most likely, so we compute the similarity.
#    b) we have a 1000 shared images across all subjects,
#       we compute the mean of the fMRI embeddings of these
#       shared images across subjects. We then do PCA and plot
#       the first 2 principal components of the mean fMRI embeddings.
# Purpose:
#    a) the similarity scores of the same image same subject would give us
#       a sense of the reliability of the fMRI embeddings generated by MindEYE2.
#    b) the similarity scores of the same image across subjects would give us
#       a sense of the consistency of the fMRI embeddings across subjects.

# Import necessary libraries
import os
import torch
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from matplotlib import pyplot as plt
from tqdm import tqdm
import typing

# --------------- Start of configuration --------------- #

# Paths to necessary files
processed_dir = "datasets/processed"
processed_dir_for_analysis = "datasets/processed/embedding_analysis"

# The subjects we want to use
# NOTE: in (nsd subject)
# NOTE: we LOOP every combination of subjects
subjects = ['sub-01', 'sub-02', 'sub-05', 'sub-07']

# Subject display colors for multi-subject plots (one per subject)
SUBJECT_COLORS = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']

# Device for processing
CUDA = 0
device = f'cuda:{CUDA}' if torch.cuda.is_available() else 'cpu'

# PLOT 1 hyperparameter
# Number of images to randomly sample for the single-subject PCA scatter.
# Set to None to visualize ALL images the subject has seen.
# A smaller value (e.g. 200) keeps the plot readable; with thousands of images
# the per-image color coding becomes indistinguishable anyway.
PLOT1_N_IMAGES: typing.Optional[int] = 200
PLOT1_RANDOM_SEED: typing.Optional[int] = 42

# ---------------- End of configuration ---------------- #

os.makedirs(processed_dir_for_analysis, exist_ok=True)


# ================================================================
# Helper: compute (or load from cache) intra-image cosine similarity
# ================================================================

def compute_intra_image_similarities(
    nsd_subject: str,
    nsd_fmri_embedding_df: pd.DataFrame,
    processed_dir_for_analysis: str,
    device: str,
) -> pd.DataFrame:
    """
    For every image in `nsd_fmri_embedding_df`, compute the pairwise cosine
    similarity across the 3 fMRI trials (sim_12, sim_13, sim_23) and their
    mean (mean_sim).

    Results are cached as a pickle file next to the other analysis artefacts.
    If the cache exists it is loaded and returned directly — no GPU work is done.

    Parameters
    ----------
    nsd_subject : str
        Subject identifier used for file naming, e.g. ``'sub-01'``.
    nsd_fmri_embedding_df : pd.DataFrame
        DataFrame with at least the columns ``fmri_embedding`` (shape ``(3, 4096)``
        per row), ``image_index``, ``subject``, ``split``, ``sample_id``,
        ``tar_path``.
    processed_dir_for_analysis : str
        Directory where the cache file is written / read from.
    device : str
        PyTorch device string, e.g. ``'cuda:0'`` or ``'cpu'``.

    Returns
    -------
    pd.DataFrame
        Columns: ``sim_12``, ``sim_13``, ``sim_23``, ``mean_sim``,
        ``image_index``, ``subject``, ``split``, ``sample_id``, ``tar_path``.
        Row order matches ``nsd_fmri_embedding_df``.
    """
    cache_path = os.path.join(
        processed_dir_for_analysis,
        f"similarity_scores_per_subject_{nsd_subject}.pkl",
    )

    # ── Cache hit ──────────────────────────────────────────────────────────
    if os.path.exists(cache_path):
        print(
            f"[{nsd_subject}] Cache found at {cache_path}. "
            f"Loading similarity scores from disk (skipping computation)."
        )
        return pd.read_pickle(cache_path)

    # ── Cache miss: compute from scratch ──────────────────────────────────
    print(f"[{nsd_subject}] No cache found. Computing intra-image similarities...")

    fmri_data_list = nsd_fmri_embedding_df['fmri_embedding'].tolist()
    fmri_data_gpu  = [torch.tensor(fd).to(device) for fd in fmri_data_list]

    rows: typing.List[typing.Tuple[float, float, float, float]] = []
    for fmri_data in tqdm(
        fmri_data_gpu,
        desc=f"Computing intra-image similarity ({nsd_subject})",
    ):
        # fmri_data: (3, 4096)
        t1 = fmri_data[0].unsqueeze(0)  # (1, 4096)
        t2 = fmri_data[1].unsqueeze(0)
        t3 = fmri_data[2].unsqueeze(0)
        sim_12 = torch.nn.functional.cosine_similarity(t1, t2).item()
        sim_13 = torch.nn.functional.cosine_similarity(t1, t3).item()
        sim_23 = torch.nn.functional.cosine_similarity(t2, t3).item()
        mean_sim = (sim_12 + sim_13 + sim_23) / 3.0
        rows.append((sim_12, sim_13, sim_23, mean_sim))

    similarity_scores_df = pd.DataFrame(
        rows, columns=['sim_12', 'sim_13', 'sim_23', 'mean_sim']
    )
    # Attach metadata columns from the source dataframe
    similarity_scores_df['image_index'] = nsd_fmri_embedding_df['image_index'].values
    similarity_scores_df['subject']     = nsd_fmri_embedding_df['subject'].values
    similarity_scores_df['split']       = nsd_fmri_embedding_df['split'].values
    similarity_scores_df['sample_id']   = nsd_fmri_embedding_df['sample_id'].values
    similarity_scores_df['tar_path']    = nsd_fmri_embedding_df['tar_path'].values

    # Persist to disk so future runs skip computation
    similarity_scores_df.to_pickle(cache_path)
    print(
        f"[{nsd_subject}] Saved similarity scores to {cache_path}."
    )
    return similarity_scores_df


# ================================================================
# Main loop: per-subject processing
# ================================================================

# Keyed by nsd_subject; stores the full embedding dataframe for each subject.
embedding_dfs: typing.Dict[str, pd.DataFrame] = {}

# Keyed by nsd_subject; stores the array of per-image mean similarities
# (row order matches the subject's embedding dataframe).
mean_similarities_per_subject_per_image: typing.Dict[str, np.ndarray] = {}

for nsd_subject in subjects:
    print(f"\n{'='*60}")
    print(f"Processing subject {nsd_subject}...")

    # ── Load embedding dataframe ───────────────────────────────────────────
    nsd_fmri_embedding_df_path = None
    for file in os.listdir(processed_dir_for_analysis):
        if (
            file.startswith(f"nsd_fmri_analysis_df_{nsd_subject}")
            and file.endswith(".pkl")
        ):
            nsd_fmri_embedding_df_path = os.path.join(
                processed_dir_for_analysis, file
            )
    if nsd_fmri_embedding_df_path is None:
        raise FileNotFoundError(
            f"Could not find the DF for analysis for subject {nsd_subject} "
            f"in {processed_dir_for_analysis}."
        )
    nsd_fmri_embedding_df: pd.DataFrame = pd.read_pickle(nsd_fmri_embedding_df_path)
    print(
        f"Loaded fMRI embedding dataframe for subject {nsd_subject} "
        f"with shape {nsd_fmri_embedding_df.shape}."
    )

    # Validate embedding shapes
    fmri_data_list = nsd_fmri_embedding_df['fmri_embedding'].tolist()
    for fmri_data in fmri_data_list:
        assert fmri_data.shape == (3, 4096), f"Unexpected shape: {fmri_data.shape}"

    # Store the full dataframe for later use in the cross-subject section
    embedding_dfs[nsd_subject] = nsd_fmri_embedding_df

    # ================================================================
    # PLOT 1: Single-subject, randomly-sampled images, all-trials scatter
    # -----------------------------------------------------------------
    # PLOT1_N_IMAGES controls how many images are visualised (None = all).
    # Each sampled image gets its own color; each trial gets its own marker.
    # Points for the same image (3 trials) should cluster together if the
    # MindEye2 embeddings are reliable (low noise across sessions).
    # NOTE: PCA is always fit on the sampled subset only, so the projection
    #       maximises variance within that subset.
    # ================================================================
    num_images_total = len(fmri_data_list)

    # Determine which image indices (into fmri_data_list) to plot
    if PLOT1_N_IMAGES is None or PLOT1_N_IMAGES >= num_images_total:
        plot1_indices = list(range(num_images_total))
        plot1_n_label = num_images_total
        print(
            f"[{nsd_subject}] PLOT 1: visualising all {num_images_total} images."
        )
    else:
        rng = np.random.default_rng(PLOT1_RANDOM_SEED)
        plot1_indices = sorted(
            rng.choice(num_images_total, size=PLOT1_N_IMAGES, replace=False).tolist()
        )
        plot1_n_label = PLOT1_N_IMAGES
        print(
            f"[{nsd_subject}] PLOT 1: randomly sampled {PLOT1_N_IMAGES} / "
            f"{num_images_total} images (seed={PLOT1_RANDOM_SEED})."
        )

    # Stack sampled embeddings to (plot1_n_label * 3, 4096)
    fmri_data_tensor_plot1 = torch.cat(
        [torch.tensor(fmri_data_list[i]) for i in plot1_indices], dim=0
    )

    pca_single = PCA(n_components=2)
    fmri_data_pca = pca_single.fit_transform(fmri_data_tensor_plot1.numpy())
    # Reshape to (plot1_n_label, 3, 2)
    fmri_data_pca = fmri_data_pca.reshape(plot1_n_label, 3, 2)

    fig, ax = plt.subplots(figsize=(12, 9))
    colors_img     = plt.cm.get_cmap('tab20', plot1_n_label)
    markers_trials = ['o', 's', 'D']
    trial_labels   = ['Trial 1', 'Trial 2', 'Trial 3']
    for trial_idx, (marker, label) in enumerate(zip(markers_trials, trial_labels)):
        ax.scatter(
            fmri_data_pca[:, trial_idx, 0],
            fmri_data_pca[:, trial_idx, 1],
            label=label,
            marker=marker,
            alpha=0.6,
            s=20,
            c=[colors_img(i) for i in range(plot1_n_label)],
        )
    ax.set_xlabel("Principal Component 1")
    ax.set_ylabel("Principal Component 2")
    ax.set_title(
        f"PCA of fMRI Embeddings – {nsd_subject}\n"
        f"({plot1_n_label} sampled images × 3 trials; "
        f"color = image, marker = trial)"
    )
    ax.legend(loc='upper right')
    ax.grid(True, alpha=0.3)
    fig.tight_layout()
    pca_plot_path = os.path.join(
        processed_dir_for_analysis,
        f"pca_fmri_embeddings_{nsd_subject}.png",
    )
    fig.savefig(pca_plot_path, dpi=150)
    plt.close(fig)
    print(f"Saved single-subject PCA scatter to {pca_plot_path}.")

    # ================================================================
    # Compute (or load) pairwise cosine similarity via helper function
    # (always computed over ALL images, not just the sampled subset)
    # ================================================================
    similarity_scores_df = compute_intra_image_similarities(
        nsd_subject=nsd_subject,
        nsd_fmri_embedding_df=nsd_fmri_embedding_df,
        processed_dir_for_analysis=processed_dir_for_analysis,
        device=device,
    )

    # Cache the mean score array (row-ordered, not by image_index)
    mean_similarities_per_subject_per_image[nsd_subject] = (
        similarity_scores_df['mean_sim'].values
    )
    del similarity_scores_df


# ================================================================
# Cross-subject single-image scatter (PLOT 2)
# -----------------------------------------------------------------
# We take the shared 1000 images and, for a manageable subset,
# run PCA across ALL subjects' embeddings together.  Each image
# gets one color; each subject gets its own marker.  Same-image
# points from different subjects should ideally cluster together
# if the embedding space is consistent across subjects.
# ================================================================
print(f"\n{'='*60}")
print("Building cross-subject analysis...")

# Load shared image indices
nsd_image_df_path = os.path.join(processed_dir, "nsd_images_df.pkl")
# Columns: image_index / image_data / image_embedding / subject / split
# subject == 'shared' for the 1000 shared images
nsd_image_df: pd.DataFrame = pd.read_pickle(nsd_image_df_path)
shared_images_df = nsd_image_df[nsd_image_df['subject'] == 'shared']
shared_image_indices = np.sort(shared_images_df['image_index'].values[:1000])
print(f"Using {len(shared_image_indices)} shared image indices for cross-subject analysis.")
del nsd_image_df

# Filter each subject's embedding DF to the shared images only
filtered_embedding_dfs: typing.Dict[str, pd.DataFrame] = {}
for nsd_subject, embedding_df in embedding_dfs.items():
    filtered_df = (
        embedding_df[embedding_df['image_index'].isin(shared_image_indices)]
        .copy()
        .sort_values(by='image_index', ascending=True)
        .reset_index(drop=True)
    )
    assert len(filtered_df) == len(shared_image_indices), (
        f"Expected {len(shared_image_indices)} shared images, "
        f"but got {len(filtered_df)} for subject {nsd_subject}."
    )
    filtered_embedding_dfs[nsd_subject] = filtered_df
    print(
        f"Filtered embedding dataframe for subject {nsd_subject} "
        f"to {len(filtered_df)} shared images."
    )

del embedding_dfs

# Compute mean embedding per (subject, image)
#   mean_fmri_embeddings[i, j] = mean over 3 trials for subject i, image j
mean_fmri_embeddings = torch.zeros(
    (len(subjects), len(shared_image_indices), 4096)
)
for i, nsd_subject in enumerate(subjects):
    fmri_embs = filtered_embedding_dfs[nsd_subject]['fmri_embedding'].values
    mean_fmri_embeddings[i] = torch.cat(
        [torch.from_numpy(emb).mean(dim=0, keepdim=True) for emb in fmri_embs],
        dim=0,
    )  # (num_shared_images, 4096)

# Fit PCA on the pooled (len(subjects) * num_shared_images, 4096) matrix
mean_fmri_flat = mean_fmri_embeddings.reshape(-1, 4096).numpy()
pca_cross = PCA(n_components=2)
pca_cross.fit(mean_fmri_flat)
mean_fmri_pca = pca_cross.transform(mean_fmri_flat).reshape(
    len(subjects), len(shared_image_indices), 2
)
print(
    f"PCA for cross-subject scatter: "
    f"explained variance = {pca_cross.explained_variance_ratio_}"
)

# Draw cross-subject scatter
subject_markers = ['o', 's', 'D', '^', 'v', '<', '>', 'p', '*', 'h']
if len(subjects) > len(subject_markers):
    raise ValueError(
        f"Number of subjects ({len(subjects)}) exceeds available markers "
        f"({len(subject_markers)}). Add more markers."
    )

colors_shared = plt.cm.get_cmap('tab20', len(shared_image_indices))
fig, ax = plt.subplots(figsize=(12, 9))
for i, nsd_subject in enumerate(subjects):
    ax.scatter(
        mean_fmri_pca[i, :, 0],
        mean_fmri_pca[i, :, 1],
        label=nsd_subject,
        marker=subject_markers[i],
        alpha=0.7,
        s=30,
        c=[colors_shared(j) for j in range(len(shared_image_indices))],
    )
ax.set_xlabel("Principal Component 1")
ax.set_ylabel("Principal Component 2")
ax.set_title(
    "Cross-Subject PCA of Mean fMRI Embeddings\n"
    "(shared images; color = image, marker = subject)"
)
ax.legend(loc='upper right')
ax.grid(True, alpha=0.3)
fig.tight_layout()
pca_cross_path = os.path.join(
    processed_dir_for_analysis,
    "pca_cross_subject_mean_fmri_embeddings.png",
)
fig.savefig(pca_cross_path, dpi=150)
plt.close(fig)
print(f"Saved cross-subject PCA scatter to {pca_cross_path}.")


# ================================================================
# PLOT 3: Per-image similarity scatter (replaces the box plot)
# -----------------------------------------------------------------
# For each shared image we already have a mean pairwise cosine
# similarity per subject (sim_12 + sim_13 + sim_23) / 3.
# We collect these values, rank images on the X-axis, and plot
# each subject's score as a colored dot.
# Subjects are additionally ranked (legend order) by ascending
# within-subject std of their mean-similarity array.
# ================================================================
print(f"\n{'='*60}")
print("Building per-image similarity scatter...")

# Reload similarity DFs from cache (guaranteed to exist after the loop above)
# and filter down to the shared images, sorted by image_index.
shared_sim_per_subject: typing.Dict[str, np.ndarray] = {}

for nsd_subject in subjects:
    cache_path = os.path.join(
        processed_dir_for_analysis,
        f"similarity_scores_per_subject_{nsd_subject}.pkl",
    )
    sim_df: pd.DataFrame = pd.read_pickle(cache_path)
    sim_df_shared = (
        sim_df[sim_df['image_index'].isin(shared_image_indices)]
        .sort_values(by='image_index', ascending=True)
        .reset_index(drop=True)
    )
    assert len(sim_df_shared) == len(shared_image_indices), (
        f"Expected {len(shared_image_indices)} shared images in similarity DF "
        f"for {nsd_subject}, got {len(sim_df_shared)}."
    )
    shared_sim_per_subject[nsd_subject] = sim_df_shared['mean_sim'].values
    del sim_df, sim_df_shared

# Rank subjects by ascending std (most consistent first in legend)
subject_stds = {
    subj: float(np.std(arr))
    for subj, arr in shared_sim_per_subject.items()
}
subjects_ranked_by_std = sorted(subjects, key=lambda s: subject_stds[s])
print("Subjects ranked by ascending std of mean-similarity (most consistent first):")
for rank, subj in enumerate(subjects_ranked_by_std, 1):
    print(f"  {rank}. {subj}  std={subject_stds[subj]:.4f}")

# Sort the X-axis by average similarity across subjects (ascending)
avg_sim_across_subjects = np.mean(
    np.stack([shared_sim_per_subject[s] for s in subjects], axis=0),
    axis=0,
)  # (num_shared_images,)
image_rank_order = np.argsort(avg_sim_across_subjects)

x_positions = np.arange(len(shared_image_indices))  # 0 … N-1

fig, ax = plt.subplots(figsize=(64, 6))
for rank_idx, nsd_subject in enumerate(subjects_ranked_by_std):
    sim_vals_sorted = shared_sim_per_subject[nsd_subject][image_rank_order]
    color = SUBJECT_COLORS[subjects.index(nsd_subject)]
    ax.scatter(
        x_positions,
        sim_vals_sorted,
        label=(
            f"{nsd_subject}  "
            f"(std={subject_stds[nsd_subject]:.4f}, "
            f"rank={rank_idx + 1})"
        ),
        color=color,
        alpha=0.55,
        s=10,
        linewidths=0,
    )

ax.set_xlabel(
    "Shared Image (ranked by mean cosine similarity across subjects, ascending)"
)
ax.set_ylabel("Mean Pairwise Cosine Similarity (across 3 trials)")
ax.set_title(
    "Per-Image Intra-Subject fMRI Embedding Consistency\n"
    "(each dot = one image for one subject; subjects ranked by std in legend)"
)
ax.legend(loc='lower right', fontsize=9)
ax.grid(True, alpha=0.3)
fig.tight_layout()

scatter_path = os.path.join(
    processed_dir_for_analysis,
    "per_image_similarity_scatter.png",
)
fig.savefig(scatter_path, dpi=150)
plt.close(fig)
print(f"Saved per-image similarity scatter to {scatter_path}.")